{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e561c460",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Loading\n",
    "\n",
    "Import necessary libraries, load the trained FlowTransformer model and its configuration, and prepare sample input data for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b278e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:42:09.134322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753202529.146421 1240450 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753202529.149917 1240450 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-22 16:42:09.163746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  0: FlowTransformer_BERT_CSE_CIC_IDS_ws8_bs128_20250722_143415.keras\n",
      "\n",
      "Selected model: FlowTransformer_BERT_CSE_CIC_IDS_ws8_bs128_20250722_143415\n",
      "Model Configuration:\n",
      "{\n",
      "  \"model_name\": \"FlowTransformer_BERT_CSE_CIC_IDS_ws8_bs128_20250722_143415\",\n",
      "  \"timestamp\": \"20250722_143415\",\n",
      "  \"model_format\": \"native_keras\",\n",
      "  \"dataset\": {\n",
      "    \"name\": \"CSE_CIC_IDS\",\n",
      "    \"path\": \"/home/joeldan/dvcon_model/FlowTransformer_Pytorch_Imp/datasets.csv\",\n",
      "    \"eval_percent\": 0.01,\n",
      "    \"eval_method\": \"LastRows\"\n",
      "  },\n",
      "  \"model_config\": {\n",
      "    \"input_encoding\": \"NoInputEncoder\",\n",
      "    \"sequential_model\": \"BasicTransformer\",\n",
      "    \"classification_head\": \"LastTokenClassificationHead\",\n",
      "    \"window_size\": 8,\n",
      "    \"mlp_layer_sizes\": [\n",
      "      128\n",
      "    ],\n",
      "    \"mlp_dropout\": 0.1\n",
      "  },\n",
      "  \"training_config\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"epochs\": 5,\n",
      "    \"steps_per_epoch\": 64,\n",
      "    \"early_stopping_patience\": 5,\n",
      "    \"final_epoch\": 4\n",
      "  },\n",
      "  \"optimizer\": \"adam\",\n",
      "  \"loss\": \"binary_crossentropy\",\n",
      "  \"metrics\": [\n",
      "    \"binary_accuracy\"\n",
      "  ]\n",
      "}\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeldan/dvcon_model/FlowTransformer_Pytorch_Imp/implementations/transformers/basic/encoder_block.py:93: UserWarning: Typically inner_dimension should be greater than or equal to the input_dimension!\n",
      "  warnings.warn(f\"Typically inner_dimension should be greater than or equal to the input_dimension!\")\n",
      "I0000 00:00:1753202531.217656 1240450 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/home/joeldan/miniconda3/envs/flowtransformer/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'block_0_transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/joeldan/miniconda3/envs/flowtransformer/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'block_1_transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/joeldan/miniconda3/envs/flowtransformer/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'block_0_transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/joeldan/miniconda3/envs/flowtransformer/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'block_1_transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_MAX_IP_PKT_L… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_128… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_256… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_LONGEST_FLOW… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_WIN_MAX_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_102… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DURATION_OUT  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_IN_BYTES      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_WIN_MAX_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DURATION_IN   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SRC_TO_DST_S… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_FLOW_DURATIO… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MIN_IP_PKT_L… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_OUT_PKTS      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_UP_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_512… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SHORTEST_FLO… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_IN_PKTS       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DST_TO_SRC_A… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_OUT_BYTES     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MAX_TTL       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DST_TO_SRC_S… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MIN_TTL       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SRC_TO_DST_A… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_CLIENT_TCP_F… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L4_SRC_PORT   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_FLAGS     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ICMP_IPV4_TY… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ICMP_TYPE     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_PROTOCOL      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SERVER_TCP_F… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L4_DST_PORT   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L7_PROTO      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_MAX_IP_PKT… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_NUM_PKTS_1… │\n",
       "│                     │                   │            │ input_NUM_PKTS_2… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_LONGEST_FL… │\n",
       "│                     │                   │            │ input_TCP_WIN_MA… │\n",
       "│                     │                   │            │ input_NUM_PKTS_1… │\n",
       "│                     │                   │            │ input_DURATION_O… │\n",
       "│                     │                   │            │ input_IN_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_TCP_WIN_MA… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_DURATION_I… │\n",
       "│                     │                   │            │ input_SRC_TO_DST… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_FLOW_DURAT… │\n",
       "│                     │                   │            │ input_MIN_IP_PKT… │\n",
       "│                     │                   │            │ input_OUT_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_NUM_PKTS_U… │\n",
       "│                     │                   │            │ input_NUM_PKTS_5… │\n",
       "│                     │                   │            │ input_SHORTEST_F… │\n",
       "│                     │                   │            │ input_IN_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ input_DST_TO_SRC… │\n",
       "│                     │                   │            │ input_OUT_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_MAX_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ input_DST_TO_SRC… │\n",
       "│                     │                   │            │ input_MIN_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ input_SRC_TO_DST… │\n",
       "│                     │                   │            │ input_CLIENT_TCP… │\n",
       "│                     │                   │            │ input_L4_SRC_POR… │\n",
       "│                     │                   │            │ input_TCP_FLAGS[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_ICMP_IPV4_… │\n",
       "│                     │                   │            │ input_ICMP_TYPE[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_PROTOCOL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ input_SERVER_TCP… │\n",
       "│                     │                   │            │ input_L4_DST_POR… │\n",
       "│                     │                   │            │ input_L7_PROTO[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_0_transforme… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">372,550</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_1_transforme… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">372,550</span> │ block_0_transfor… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block_1_transfor… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classification_mlp… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │ slice_last[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ classification_m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ binary_classificat… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_MAX_IP_PKT_L… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_128… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_256… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_LONGEST_FLOW… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_WIN_MAX_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_102… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DURATION_OUT  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_IN_BYTES      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_WIN_MAX_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DURATION_IN   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SRC_TO_DST_S… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_RETRANSMITTE… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_FLOW_DURATIO… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MIN_IP_PKT_L… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_OUT_PKTS      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_UP_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_NUM_PKTS_512… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SHORTEST_FLO… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_IN_PKTS       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DST_TO_SRC_A… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_OUT_BYTES     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MAX_TTL       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_DST_TO_SRC_S… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_MIN_TTL       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SRC_TO_DST_A… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_CLIENT_TCP_F… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L4_SRC_PORT   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_TCP_FLAGS     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ICMP_IPV4_TY… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_ICMP_TYPE     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_PROTOCOL      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_SERVER_TCP_F… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L4_DST_PORT   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_L7_PROTO      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m289\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_MAX_IP_PKT… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_NUM_PKTS_1… │\n",
       "│                     │                   │            │ input_NUM_PKTS_2… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_LONGEST_FL… │\n",
       "│                     │                   │            │ input_TCP_WIN_MA… │\n",
       "│                     │                   │            │ input_NUM_PKTS_1… │\n",
       "│                     │                   │            │ input_DURATION_O… │\n",
       "│                     │                   │            │ input_IN_BYTES[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_TCP_WIN_MA… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_DURATION_I… │\n",
       "│                     │                   │            │ input_SRC_TO_DST… │\n",
       "│                     │                   │            │ input_RETRANSMIT… │\n",
       "│                     │                   │            │ input_FLOW_DURAT… │\n",
       "│                     │                   │            │ input_MIN_IP_PKT… │\n",
       "│                     │                   │            │ input_OUT_PKTS[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_NUM_PKTS_U… │\n",
       "│                     │                   │            │ input_NUM_PKTS_5… │\n",
       "│                     │                   │            │ input_SHORTEST_F… │\n",
       "│                     │                   │            │ input_IN_PKTS[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ input_DST_TO_SRC… │\n",
       "│                     │                   │            │ input_OUT_BYTES[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_MAX_TTL[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ input_DST_TO_SRC… │\n",
       "│                     │                   │            │ input_MIN_TTL[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ input_SRC_TO_DST… │\n",
       "│                     │                   │            │ input_CLIENT_TCP… │\n",
       "│                     │                   │            │ input_L4_SRC_POR… │\n",
       "│                     │                   │            │ input_TCP_FLAGS[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_ICMP_IPV4_… │\n",
       "│                     │                   │            │ input_ICMP_TYPE[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_PROTOCOL[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ input_SERVER_TCP… │\n",
       "│                     │                   │            │ input_L4_DST_POR… │\n",
       "│                     │                   │            │ input_L7_PROTO[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_0_transforme… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m289\u001b[0m)    │    \u001b[38;5;34m372,550\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ block_1_transforme… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m289\u001b[0m)    │    \u001b[38;5;34m372,550\u001b[0m │ block_0_transfor… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ slice_last (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m289\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ block_1_transfor… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classification_mlp… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m37,120\u001b[0m │ slice_last[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ classification_m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ binary_classificat… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,347,049</span> (8.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,347,049\u001b[0m (8.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">782,349</span> (2.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m782,349\u001b[0m (2.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,564,700</span> (5.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,564,700\u001b[0m (5.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input shape: [(None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 1), (None, 8, 32), (None, 8, 32), (None, 8, 32), (None, 8, 32), (None, 8, 32), (None, 8, 5), (None, 8, 32), (None, 8, 32), (None, 8, 32)]\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for profiling and model loading\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "# Import custom components (adjust as needed for your repo structure)\n",
    "from framework.flow_transformer import FlowTransformer\n",
    "from implementations.transformers.basic_transformers import TransformerEncoderBlock\n",
    "\n",
    "# List available models\n",
    "models_dir = \"saved_models\"\n",
    "model_files = [f for f in os.listdir(models_dir) if f.endswith(\".keras\")]\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(\"No saved models found in the 'saved_models' directory.\")\n",
    "\n",
    "print(\"Available models:\")\n",
    "for i, model_file in enumerate(model_files):\n",
    "    print(f\"  {i}: {model_file}\")\n",
    "\n",
    "# Select the first model for analysis\n",
    "selected_model_index = 0\n",
    "selected_model_file = model_files[selected_model_index]\n",
    "model_name = os.path.splitext(selected_model_file)[0]\n",
    "model_path = os.path.join(models_dir, selected_model_file)\n",
    "config_path = os.path.join(models_dir, f\"{model_name}_config.json\")\n",
    "\n",
    "# Load model configuration\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"\\nSelected model: {model_name}\")\n",
    "print(\"Model Configuration:\")\n",
    "print(json.dumps(config, indent=2))\n",
    "\n",
    "# Load the Keras model\n",
    "print(\"Loading model...\")\n",
    "model = tf.keras.models.load_model(\n",
    "    model_path,\n",
    "    custom_objects={'TransformerEncoderBlock': TransformerEncoderBlock},\n",
    "    safe_mode=False\n",
    ")\n",
    "print(\"Model loaded successfully.\")\n",
    "model.summary()\n",
    "\n",
    "# Prepare sample input data for profiling\n",
    "# Use the same input shape as the model expects (adjust as needed)\n",
    "input_shape = model.input_shape\n",
    "batch_size = config['training_config']['batch_size'] if 'training_config' in config else 32\n",
    "sample_input = [np.random.rand(batch_size, *shape[1:]).astype(np.float32) for shape in input_shape] if isinstance(input_shape, list) else np.random.rand(batch_size, *input_shape[1:]).astype(np.float32)\n",
    "print(f\"Sample input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aee5ec",
   "metadata": {},
   "source": [
    "## 2. Define Profiling Utilities\n",
    "\n",
    "Create helper functions to measure execution time accurately, including warm-up iterations and GPU synchronization if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e31940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling utilities\n",
    "import gc\n",
    "\n",
    "def time_function(func, *args, warmup=5, repeat=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Times the execution of a function, with warm-up iterations and GPU synchronization.\n",
    "    Returns average time in seconds.\n",
    "    \"\"\"\n",
    "    # Warm-up\n",
    "    for _ in range(warmup):\n",
    "        func(*args, **kwargs)\n",
    "    gc.collect()\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "    times = []\n",
    "    for _ in range(repeat):\n",
    "        start = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        # GPU synchronization is handled automatically in TensorFlow 2.x\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "    avg_time = sum(times) / len(times)\n",
    "    print(f\"Average time over {repeat} runs: {avg_time:.6f} seconds\")\n",
    "    return avg_time\n",
    "\n",
    "# Example usage:\n",
    "# avg = time_function(model.predict, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc2e47",
   "metadata": {},
   "source": [
    "## 3. Profile End-to-End MHA Latency\n",
    "\n",
    "Isolate a single TransformerEncoderBlock from the loaded model and measure the average forward pass time for the Multi-Head Attention block using sample input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccefe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling model inference. TensorBoard logs will be saved to: ./tf_profiler_logs/20250722-164212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:42:12.398681: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2025-07-22 16:42:12.398739: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
      "2025-07-22 16:42:12.398821: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1006] Profiler found 1 GPUs\n",
      "/home/joeldan/miniconda3/envs/flowtransformer/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['input_MAX_IP_PKT_LEN', 'input_NUM_PKTS_128_TO_256_BYTES', 'input_NUM_PKTS_256_TO_512_BYTES', 'input_RETRANSMITTED_OUT_PKTS', 'input_LONGEST_FLOW_PKT', 'input_TCP_WIN_MAX_OUT', 'input_NUM_PKTS_1024_TO_1514_BYTES', 'input_DURATION_OUT', 'input_IN_BYTES', 'input_RETRANSMITTED_IN_PKTS', 'input_TCP_WIN_MAX_IN', 'input_RETRANSMITTED_OUT_BYTES', 'input_DURATION_IN', 'input_SRC_TO_DST_SECOND_BYTES', 'input_RETRANSMITTED_IN_BYTES', 'input_FLOW_DURATION_MILLISECONDS', 'input_MIN_IP_PKT_LEN', 'input_OUT_PKTS', 'input_NUM_PKTS_UP_TO_128_BYTES', 'input_NUM_PKTS_512_TO_1024_BYTES', 'input_SHORTEST_FLOW_PKT', 'input_IN_PKTS', 'input_DST_TO_SRC_AVG_THROUGHPUT', 'input_OUT_BYTES', 'input_MAX_TTL', 'input_DST_TO_SRC_SECOND_BYTES', 'input_MIN_TTL', 'input_SRC_TO_DST_AVG_THROUGHPUT', 'input_CLIENT_TCP_FLAGS', 'input_L4_SRC_PORT', 'input_TCP_FLAGS', 'input_ICMP_IPV4_TYPE', 'input_ICMP_TYPE', 'input_PROTOCOL', 'input_SERVER_TCP_FLAGS', 'input_L4_DST_PORT', 'input_L7_PROTO']. Received: the structure of inputs=('*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*')\n",
      "  warnings.warn(\n",
      "I0000 00:00:1753202532.770027 1240539 service.cc:148] XLA service 0x2d54ba20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753202532.770080 1240539 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-22 16:42:12.787308: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753202532.834329 1240539 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "I0000 00:00:1753202532.770027 1240539 service.cc:148] XLA service 0x2d54ba20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753202532.770080 1240539 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-22 16:42:12.787308: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753202532.834329 1240539 cuda_dnn.cc:529] Loaded cuDNN version 90101\n",
      "2025-07-22 16:42:14.101111: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.101111: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.392440: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 1040 bytes spill stores, 1040 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.449874: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16_0', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.392440: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 1040 bytes spill stores, 1040 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.449874: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16_0', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.852930: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.914028: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16_0', 712 bytes spill stores, 712 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.982865: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 536 bytes spill stores, 536 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.852930: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.914028: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16_0', 712 bytes spill stores, 712 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:14.982865: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 536 bytes spill stores, 536 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:15.229763: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 228 bytes spill stores, 296 bytes spill loads\n",
      "\n",
      "2025-07-22 16:42:15.229763: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 228 bytes spill stores, 296 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
      "Profiling complete. To view per-layer timings (including MHA), run: tensorboard --logdir ./tf_profiler_logs/20250722-164212\n",
      "Profiling complete. To view per-layer timings (including MHA), run: tensorboard --logdir ./tf_profiler_logs/20250722-164212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753202536.323617 1240539 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-07-22 16:42:16.374208: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
      "2025-07-22 16:42:16.378249: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1213] CUPTI activity buffer flushed\n",
      "2025-07-22 16:42:16.393290: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:635]  GpuTracer has collected 1970 callback api events and 1460 activity events. \n",
      "2025-07-22 16:42:16.393359: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:638]  GpuTracer max callback_events: 2097152, max activity events: 2097152\n",
      "2025-07-22 16:42:16.400000: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2025-07-22 16:42:16.402211: I external/local_xla/xla/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: ./tf_profiler_logs/20250722-164212/plugins/profile/2025_07_22_16_42_16/joels-loq.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "# Profile MHA and all layers using TensorFlow Profiler during a real inference pass\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "logdir = \"./tf_profiler_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tf.profiler.experimental.start(logdir)\n",
    "\n",
    "print(f\"Profiling model inference. TensorBoard logs will be saved to: {logdir}\")\n",
    "\n",
    "# Use a real batch for profiling (from previous cell, or fallback to sample_input)\n",
    "profile_input = sample_input\n",
    "try:\n",
    "    if 'eval_X' in locals():\n",
    "        profile_input = eval_X\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "model.predict(profile_input)\n",
    "tf.profiler.experimental.stop()\n",
    "print(f\"Profiling complete. To view per-layer timings (including MHA), run: tensorboard --logdir {logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157066ea",
   "metadata": {},
   "source": [
    "## 4. Profile Total Inference Time and Throughput\n",
    "\n",
    "Run inference on the full model using a batch of sample data. Measure the average time per batch to find the total inference time. Calculate throughput as (batch_size / inference_time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2604260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Average time over 10 runs: 0.180447 seconds\n",
      "Average total inference time per batch: 0.180447 seconds\n",
      "Throughput: 709.35 samples/second\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Average time over 10 runs: 0.180447 seconds\n",
      "Average total inference time per batch: 0.180447 seconds\n",
      "Throughput: 709.35 samples/second\n"
     ]
    }
   ],
   "source": [
    "# Profile total inference time for the full model\n",
    "inference_time = time_function(model.predict, sample_input)\n",
    "print(f\"Average total inference time per batch: {inference_time:.6f} seconds\")\n",
    "\n",
    "# Calculate throughput (samples per second)\n",
    "throughput = batch_size / inference_time\n",
    "print(f\"Throughput: {throughput:.2f} samples/second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470f3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache file path: cache/CSE_CIC_IDS_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_VHNk9ujbqtTXGSrgVayeqG486IQ0.feather\n",
      "Reading directly from cache cache/CSE_CIC_IDS_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_VHNk9ujbqtTXGSrgVayeqG486IQ0.feather...\n",
      "Dataset loaded.\n",
      "Dataset loaded.\n",
      "Prepared real batch for profiling: 37 features, batch size 128\n",
      "Error during MHA profiling with real data: No module named 'tensorflow.keras'\n",
      "Prepared real batch for profiling: 37 features, batch size 128\n",
      "Error during MHA profiling with real data: No module named 'tensorflow.keras'\n"
     ]
    }
   ],
   "source": [
    "# --- Extract a real batch from the dataset and profile the MHA block ---\n",
    "# Assumes you have loaded or can load the dataset as in your analysis notebook\n",
    "try:\n",
    "    # Load dataset using FlowTransformer (reuse logic from your analysis notebook)\n",
    "    from framework.dataset_specification import NamedDatasetSpecifications\n",
    "    from framework.enumerations import EvaluationDatasetSampling\n",
    "    from framework.flow_transformer_parameters import FlowTransformerParameters\n",
    "    from implementations.classification_heads import *\n",
    "    from implementations.input_encodings import *\n",
    "    from implementations.pre_processings import StandardPreProcessing\n",
    "    from implementations.transformers.basic_transformers import *\n",
    "    from implementations.transformers.named_transformers import *\n",
    "\n",
    "    # Map component names from config to actual classes\n",
    "    all_components = {\n",
    "        \"pre_processing\": {\n",
    "            \"StandardPreProcessing\": StandardPreProcessing(n_categorical_levels=32)\n",
    "        },\n",
    "        \"input_encoding\": {\n",
    "            \"NoInputEncoder\": NoInputEncoder(),\n",
    "            \"RecordLevelEmbed\": RecordLevelEmbed(64),\n",
    "            \"CategoricalFeatureEmbed\": CategoricalFeatureEmbed(EmbedLayerType.Dense, 16),\n",
    "        },\n",
    "        \"sequential_model\": {\n",
    "            \"BasicTransformer\": BasicTransformer(2, 128, n_heads=2),\n",
    "            \"GPTSmallTransformer\": GPTSmallTransformer(),\n",
    "            \"BERTSmallTransformer\": BERTSmallTransformer()\n",
    "        },\n",
    "        \"classification_head\": {\n",
    "            \"LastTokenClassificationHead\": LastTokenClassificationHead(),\n",
    "            \"FlattenClassificationHead\": FlattenClassificationHead(),\n",
    "            \"GlobalAveragePoolingClassificationHead\": GlobalAveragePoolingClassificationHead(),\n",
    "            \"CLSTokenClassificationHead\": CLSTokenClassificationHead(),\n",
    "            \"FeaturewiseEmbedding\": FeaturewiseEmbedding(project=False),\n",
    "        }\n",
    "    }\n",
    "    model_config = config['model_config']\n",
    "    ft = FlowTransformer(\n",
    "        pre_processing=all_components[\"pre_processing\"][\"StandardPreProcessing\"],\n",
    "        input_encoding=all_components[\"input_encoding\"][model_config['input_encoding']],\n",
    "        sequential_model=all_components[\"sequential_model\"][model_config['sequential_model']],\n",
    "        classification_head=all_components[\"classification_head\"][model_config['classification_head']],\n",
    "        params=FlowTransformerParameters(\n",
    "            window_size=model_config['window_size'],\n",
    "            mlp_layer_sizes=model_config['mlp_layer_sizes'],\n",
    "            mlp_dropout=model_config['mlp_dropout']\n",
    "        )\n",
    "    )\n",
    "    dataset_config = config['dataset']\n",
    "    dataset_spec_map = {\n",
    "        \"unified_flow_format\": NamedDatasetSpecifications.unified_flow_format,\n",
    "        \"nsl_kdd\": NamedDatasetSpecifications.nsl_kdd,\n",
    "        \"CSE_CIC_IDS\": NamedDatasetSpecifications.unified_flow_format\n",
    "    }\n",
    "    ft.load_dataset(\n",
    "        dataset_config['name'],\n",
    "        \"datasets.csv\",\n",
    "        dataset_spec_map[dataset_config['name']],\n",
    "        evaluation_dataset_sampling=EvaluationDatasetSampling[dataset_config['eval_method']],\n",
    "        evaluation_percent=dataset_config['eval_percent']\n",
    "    )\n",
    "    print(\"Dataset loaded.\")\n",
    "\n",
    "    # Prepare a real batch for profiling\n",
    "    from framework.enumerations import CategoricalFormat\n",
    "    selectable_mask = np.zeros(len(ft.X), dtype=bool)\n",
    "    selectable_mask[ft.parameters.window_size:-ft.parameters.window_size] = True\n",
    "    train_mask = ft.training_mask\n",
    "    indices_test = np.argwhere(~train_mask & selectable_mask).reshape(-1)\n",
    "    def get_windows_for_indices(indices):\n",
    "        X_windows = []\n",
    "        for i1 in indices:\n",
    "            X_windows.append(ft.X.iloc[(i1 - ft.parameters.window_size) + 1:i1 + 1])\n",
    "        return X_windows\n",
    "    feature_columns_map = {}\n",
    "    def samplewise_to_featurewise(X_windows):\n",
    "        sequence_length = len(X_windows[0])\n",
    "        combined_df = pd.concat(X_windows)\n",
    "        featurewise_X = []\n",
    "        if len(feature_columns_map) == 0:\n",
    "            for feature in ft.model_input_spec.feature_names:\n",
    "                if feature in ft.model_input_spec.numeric_feature_names or ft.model_input_spec.categorical_format == CategoricalFormat.Integers:\n",
    "                    feature_columns_map[feature] = feature\n",
    "                else:\n",
    "                    feature_columns_map[feature] = [c for c in X_windows[0].columns if str(c).startswith(feature)]\n",
    "        for feature in ft.model_input_spec.feature_names:\n",
    "            feature_columns = feature_columns_map[feature]\n",
    "            combined_values = combined_df[feature_columns].values\n",
    "            reshaped_values = np.array([combined_values[i:i+sequence_length] for i in range(0, len(combined_values), sequence_length)])\n",
    "            featurewise_X.append(reshaped_values)\n",
    "        return featurewise_X\n",
    "    eval_X_windows = get_windows_for_indices(indices_test[:batch_size])\n",
    "    eval_X = samplewise_to_featurewise(eval_X_windows)\n",
    "    print(f\"Prepared real batch for profiling: {len(eval_X)} features, batch size {batch_size}\")\n",
    "\n",
    "    # Pass through the model up to the MHA block\n",
    "    # Find the index of the MHA block\n",
    "    mha_index = None\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if isinstance(layer, TransformerEncoderBlock):\n",
    "            mha_index = idx\n",
    "            break\n",
    "    if mha_index is None:\n",
    "        raise ValueError(\"No TransformerEncoderBlock found in the model.\")\n",
    "    # Create a sub-model up to the MHA block\n",
    "    from tensorflow.keras import Model\n",
    "    sub_model = Model(inputs=model.inputs, outputs=model.layers[mha_index].output)\n",
    "    mha_input = sub_model.predict(eval_X)\n",
    "    print(f\"Input shape for MHA block: {mha_input.shape}\")\n",
    "\n",
    "    # Profile the MHA block with correct input\n",
    "    mha_latency = time_function(mha_block, mha_input)\n",
    "    print(f\"Average latency per matmul (MHA block, real data): {mha_latency:.6f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during MHA profiling with real data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c05476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling model inference. TensorBoard logs will be saved to: ./tf_profiler_logs/20250722-164219\n",
      "profile_input type: <class 'list'>\n",
      "Input 0 shape: (128, 8), dtype: float32\n",
      "Input 1 shape: (128, 8), dtype: float32\n",
      "Input 2 shape: (128, 8), dtype: float32\n",
      "Input 3 shape: (128, 8), dtype: float32\n",
      "Input 4 shape: (128, 8), dtype: float32\n",
      "Input 5 shape: (128, 8), dtype: float32\n",
      "Input 6 shape: (128, 8), dtype: float32\n",
      "Input 7 shape: (128, 8), dtype: float32\n",
      "Input 8 shape: (128, 8), dtype: float32\n",
      "Input 9 shape: (128, 8), dtype: float32\n",
      "Input 10 shape: (128, 8), dtype: float32\n",
      "Input 11 shape: (128, 8), dtype: float32\n",
      "Input 12 shape: (128, 8), dtype: float32\n",
      "Input 13 shape: (128, 8), dtype: float32\n",
      "Input 14 shape: (128, 8), dtype: float32\n",
      "Input 15 shape: (128, 8), dtype: float32\n",
      "Input 16 shape: (128, 8), dtype: float32\n",
      "Input 17 shape: (128, 8), dtype: float32\n",
      "Input 18 shape: (128, 8), dtype: float32\n",
      "Input 19 shape: (128, 8), dtype: float32\n",
      "Input 20 shape: (128, 8), dtype: float32\n",
      "Input 21 shape: (128, 8), dtype: float32\n",
      "Input 22 shape: (128, 8), dtype: float32\n",
      "Input 23 shape: (128, 8), dtype: float32\n",
      "Input 24 shape: (128, 8), dtype: float32\n",
      "Input 25 shape: (128, 8), dtype: float32\n",
      "Input 26 shape: (128, 8), dtype: float32\n",
      "Input 27 shape: (128, 8), dtype: float32\n",
      "Input 28 shape: (128, 8, 32), dtype: bool\n",
      "Input 29 shape: (128, 8, 32), dtype: bool\n",
      "Input 30 shape: (128, 8, 32), dtype: bool\n",
      "Input 31 shape: (128, 8, 32), dtype: bool\n",
      "Input 32 shape: (128, 8, 32), dtype: bool\n",
      "Input 33 shape: (128, 8, 5), dtype: bool\n",
      "Input 34 shape: (128, 8, 32), dtype: bool\n",
      "Input 35 shape: (128, 8, 32), dtype: bool\n",
      "Input 36 shape: (128, 8, 32), dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:42:19.603539: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
      "2025-07-22 16:42:19.603606: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling complete. To view per-layer timings, run: tensorboard --logdir ./tf_profiler_logs/20250722-164219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 16:42:20.242797: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
      "2025-07-22 16:42:20.246383: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1213] CUPTI activity buffer flushed\n",
      "2025-07-22 16:42:20.255341: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:635]  GpuTracer has collected 148 callback api events and 170 activity events. \n",
      "2025-07-22 16:42:20.255403: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:638]  GpuTracer max callback_events: 2097152, max activity events: 2097152\n",
      "2025-07-22 16:42:20.257606: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
      "2025-07-22 16:42:20.259070: I external/local_xla/xla/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: ./tf_profiler_logs/20250722-164219/plugins/profile/2025_07_22_16_42_20/joels-loq.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "# --- Improved TensorFlow Profiler usage: warm-up and multiple steps ---\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "logdir = \"./tf_profiler_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(f\"Profiling model inference. TensorBoard logs will be saved to: {logdir}\")\n",
    "\n",
    "# Use a real batch for profiling (from previous cell, or fallback to sample_input)\n",
    "profile_input = sample_input\n",
    "try:\n",
    "    if 'eval_X' in locals():\n",
    "        profile_input = eval_X\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Debug: print input type and shape\n",
    "print(\"profile_input type:\", type(profile_input))\n",
    "if isinstance(profile_input, list):\n",
    "    for i, arr in enumerate(profile_input):\n",
    "        print(f\"Input {i} shape: {arr.shape}, dtype: {arr.dtype}\")\n",
    "else:\n",
    "    print(\"Input shape:\", profile_input.shape, \"dtype:\", profile_input.dtype)\n",
    "\n",
    "# Warm-up (not profiled)\n",
    "for _ in range(5):\n",
    "    _ = model(profile_input)\n",
    "\n",
    "tf.profiler.experimental.start(logdir)\n",
    "for _ in range(10):\n",
    "    _ = model(profile_input)\n",
    "tf.profiler.experimental.stop()\n",
    "print(f\"Profiling complete. To view per-layer timings, run: tensorboard --logdir {logdir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowtransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
